# OpenTelemetry Collector Configuration for Task-Master System
# Implements MELT data collection, processing, and export
# Based on research-driven atomic task breakdown

# Receivers: Data collection entry points
receivers:
  # OTLP receiver for application telemetry
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318
        cors:
          allowed_origins:
            - "http://localhost:*"
            - "https://localhost:*"
  
  # Prometheus metrics scraping
  prometheus:
    config:
      scrape_configs:
        - job_name: 'task-master-metrics'
          scrape_interval: 15s
          static_configs:
            - targets: ['localhost:8080']
              labels:
                service: 'task-master'
                environment: 'development'
  
  # Host metrics for system observability
  hostmetrics:
    collection_interval: 30s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
      disk:
        metrics:
          system.disk.io:
            enabled: true
      network:
        metrics:
          system.network.io:
            enabled: true
      load:
        metrics:
          system.cpu.load_average.1m:
            enabled: true
  
  # File log receiver for application logs
  filelog:
    include:
      - /var/log/task-master/*.log
      - ./.taskmaster/logs/*.log
    include_file_name: false
    include_file_path: true
    operators:
      # Parse JSON logs
      - type: json_parser
        id: json_parser
        if: 'body matches "^\\{"'
      # Extract trace context from logs
      - type: regex_parser
        id: trace_extractor
        regex: 'trace_id=(?P<trace_id>[a-f0-9]{32})'
        parse_from: attributes.message
      # Add parsed trace_id to span context
      - type: move
        from: attributes.trace_id
        to: attributes["trace.trace_id"]

# Processors: Data transformation and enrichment
processors:
  # Batch processor for performance optimization
  batch:
    timeout: 1s
    send_batch_size: 1024
    send_batch_max_size: 2048
  
  # Memory limiter to prevent OOM
  memory_limiter:
    limit_mib: 512
    spike_limit_mib: 128
  
  # Resource processor for service metadata
  resource:
    attributes:
      - key: service.namespace
        value: "task-master"
        action: insert
      - key: deployment.environment
        from_attribute: "environment"
        action: insert
      - key: service.instance.id
        from_attribute: "host.name"
        action: insert
  
  # Attributes processor for data enrichment
  attributes:
    actions:
      # Add task-master specific attributes
      - key: task.master.version
        value: "1.0.0"
        action: insert
      - key: task.master.component
        from_attribute: "component"
        action: insert
      # Normalize service names
      - key: service.name
        from_attribute: "service_name"
        action: update
  
  # Span processor for trace enhancement
  span:
    name:
      # Normalize span names
      to_attributes:
        rules:
          - ^(.*)\.(.*)\.(.*)$
    rename:
      from_attributes: ["http.method", "http.route"]
      separator: " "

# Exporters: Data export destinations
exporters:
  # OTLP exporter for observability backends
  otlp:
    endpoint: "http://jaeger:14250"
    tls:
      insecure: true
    headers:
      "api-key": "${OBSERVABILITY_API_KEY}"
  
  # Prometheus exporter for metrics
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "task_master"
    const_labels:
      environment: "development"
      service_namespace: "task-master"
  
  # File exporter for debugging
  file:
    path: "./.taskmaster/logs/telemetry.json"
    rotation:
      max_megabytes: 100
      max_days: 7
      max_backups: 3
  
  # Logging exporter for development
  logging:
    loglevel: info
    sampling_initial: 2
    sampling_thereafter: 500
  
  # Jaeger exporter for distributed tracing
  jaeger:
    endpoint: "http://jaeger:14250"
    tls:
      insecure: true
  
  # OTLP HTTP exporter for cloud backends
  otlphttp:
    endpoint: "https://api.honeycomb.io"
    headers:
      "x-honeycomb-team": "${HONEYCOMB_API_KEY}"
      "x-honeycomb-dataset": "task-master"

# Extensions: Collector extensions
extensions:
  # Health check extension
  health_check:
    endpoint: 0.0.0.0:13133
    path: "/health"
  
  # pprof extension for performance profiling
  pprof:
    endpoint: 0.0.0.0:1777
  
  # zpages extension for live debugging
  zpages:
    endpoint: 0.0.0.0:55679

# Service: Pipeline configuration
service:
  extensions: [health_check, pprof, zpages]
  
  pipelines:
    # Traces pipeline
    traces:
      receivers: [otlp]
      processors: [memory_limiter, resource, attributes, span, batch]
      exporters: [otlp, jaeger, logging]
    
    # Metrics pipeline
    metrics:
      receivers: [otlp, prometheus, hostmetrics]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [prometheus, otlp, logging]
    
    # Logs pipeline
    logs:
      receivers: [otlp, filelog]
      processors: [memory_limiter, resource, attributes, batch]
      exporters: [otlp, file, logging]
  
  # Telemetry configuration for collector self-monitoring
  telemetry:
    logs:
      level: "info"
    metrics:
      address: 0.0.0.0:8888
      level: "detailed"
    traces:
      processors: [batch]
      exporters: [logging]